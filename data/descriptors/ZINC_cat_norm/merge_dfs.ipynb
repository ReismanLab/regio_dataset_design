{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "34d4c0b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "ZINC_DIR = \".\"  # ZINC_cat_norm (this folder)\n",
        "PREPROCESSED_DIR = \"../preprocessed_reactions_no_unspec_no_intra_unnorm\"\n",
        "OUT_DIR = \".\"  # output subfolder\n",
        "\n",
        "# Columns to exclude from min-max normalization (identifiers, labels, categorical)\n",
        "COLS_EXCLUDE = [\"Reactant_SMILES\", \"Atom_nº\", \"Selectivity\", \"Reactive Atom\", \"DOI\", \"source\"]\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def minmax_normalize(df, cols_exclude):\n",
        "    \"\"\"Min-max normalization to [0, 1] for numeric columns. Constant columns -> 0.\"\"\"\n",
        "    out = df.copy()\n",
        "    for col in out.columns:\n",
        "        if col in cols_exclude or col not in out.select_dtypes(include=[np.number]).columns:\n",
        "            continue\n",
        "        mn, mx = out[col].min(), out[col].max()\n",
        "        if mx > mn:\n",
        "            out[col] = (out[col] - mn) / (mx - mn)\n",
        "        else:\n",
        "            out[col] = 0.0\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "957ef8c3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matching dataframes: ['df_bde.csv', 'df_custom.csv', 'df_en1.csv', 'df_en1_ohe.csv', 'df_gas.csv', 'df_rdkVbur.csv', 'df_xtb.csv']\n"
          ]
        }
      ],
      "source": [
        "# Get CSV names in both folders (match by filename)\n",
        "zinc_files = [f for f in os.listdir(ZINC_DIR) if f.endswith(\".csv\") and f.startswith(\"df_\")]\n",
        "preprocessed_files = set(os.listdir(PREPROCESSED_DIR))\n",
        "common = [f for f in zinc_files if f in preprocessed_files]\n",
        "print(f\"Matching dataframes: {sorted(common)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cc086c2b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Dropped 3823 duplicate (SMILES, Atom_nº) rows\n",
            "df_bde.csv: -> 281411 rows, 12 cols (deduped, min-max normalized)\n",
            "  Dropped 3823 duplicate (SMILES, Atom_nº) rows\n",
            "df_custom.csv: -> 281267 rows, 11 cols (deduped, min-max normalized)\n",
            "  Dropped 3823 duplicate (SMILES, Atom_nº) rows\n",
            "df_en1.csv: -> 281417 rows, 14 cols (deduped, min-max normalized)\n",
            "  Dropped 3823 duplicate (SMILES, Atom_nº) rows\n",
            "df_en1_ohe.csv: -> 281417 rows, 55 cols (deduped, min-max normalized)\n",
            "  Dropped 3823 duplicate (SMILES, Atom_nº) rows\n",
            "df_gas.csv: -> 281402 rows, 10 cols (deduped, min-max normalized)\n",
            "  Dropped 3823 duplicate (SMILES, Atom_nº) rows\n",
            "df_rdkVbur.csv: -> 281283 rows, 14 cols (deduped, min-max normalized)\n",
            "  Dropped 3823 duplicate (SMILES, Atom_nº) rows\n",
            "df_xtb.csv: -> 281288 rows, 42 cols (deduped, min-max normalized)\n"
          ]
        }
      ],
      "source": [
        "for name in sorted(common):\n",
        "    df_zinc = pd.read_csv(os.path.join(ZINC_DIR, name), index_col=0, low_memory=False)\n",
        "    df_pre = pd.read_csv(os.path.join(PREPROCESSED_DIR, name), index_col=0, low_memory=False)\n",
        "\n",
        "    df_zinc[\"source\"] = \"ZINC_cat_norm\"\n",
        "    df_pre[\"source\"] = \"preprocessed_reactions_no_unspec_no_intra_unnorm\"\n",
        "\n",
        "    # Union of columns: align and concat along rows\n",
        "    all_cols = list(df_zinc.columns) + [c for c in df_pre.columns if c not in df_zinc.columns]\n",
        "    for c in all_cols:\n",
        "        if c not in df_zinc.columns:\n",
        "            df_zinc[c] = pd.NA\n",
        "        if c not in df_pre.columns:\n",
        "            df_pre[c] = pd.NA\n",
        "    df_merged = pd.concat([df_zinc[all_cols], df_pre[all_cols]], axis=0, ignore_index=True)\n",
        "\n",
        "    # Remove duplicate (Reactant_SMILES, Atom_nº), keep first\n",
        "    key_cols = [c for c in [\"Reactant_SMILES\", \"Atom_nº\"] if c in df_merged.columns]\n",
        "    if key_cols:\n",
        "        n_before = len(df_merged)\n",
        "        df_merged = df_merged.drop_duplicates(subset=key_cols, keep=\"first\")\n",
        "        n_dropped = n_before - len(df_merged)\n",
        "        if n_dropped:\n",
        "            print(f\"  Dropped {n_dropped} duplicate (SMILES, Atom_nº) rows\")\n",
        "\n",
        "    # Min-max normalize numeric columns to [0, 1]\n",
        "    df_merged = minmax_normalize(df_merged, COLS_EXCLUDE)\n",
        "\n",
        "    out_path = os.path.join(OUT_DIR, name)\n",
        "    df_merged.to_csv(out_path)\n",
        "    print(f\"{name}: -> {len(df_merged)} rows, {len(all_cols)} cols (deduped, min-max normalized)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09f20914",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "regio_ch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
