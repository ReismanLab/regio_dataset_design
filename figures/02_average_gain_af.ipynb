{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rxn = \"borylation\"\n",
    "rxn = \"dioxirane\"\n",
    "if rxn == \"dioxirane\":\n",
    "    df     = pd.read_csv('../active_learning/regression/perf_clean_run.csv')\n",
    "    max_   = 135\n",
    "    rxn_lm = 50\n",
    "elif rxn == \"borylation\":\n",
    "    df     = pd.read_csv('../active_learning/regression/perf_clean_run_borylation_db0-01_a1.csv')\n",
    "    max_   = 60\n",
    "    rxn_lm = 22\n",
    "\n",
    "print(f\"Random reaching accuracy: {rxn_lm - df.random.to_list().count(135)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_vs_random(af, df=df, output=\"mean\", max_=135):\n",
    "    df_ = df[[af, 'random']]\n",
    "    diff = []\n",
    "    for i in range(len(df_)):\n",
    "        if df_[af][i] == max_ and df_['random'][i] == max_: # both are not reaching the accuracy any points\n",
    "            diff.append(np.nan)\n",
    "        else:\n",
    "            diff.append(df_['random'][i] - df_[af][i]) # one of them is reaching the accuracy\n",
    "    if output == \"median\":\n",
    "        return np.median(diff)\n",
    "    elif output == \"mean\":\n",
    "        return np.mean(diff)\n",
    "    elif output == \"diff\":\n",
    "        return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = pd.DataFrame()\n",
    "for col in df.columns:\n",
    "    if 'acqf' in col:\n",
    "        df_diff[col] = get_avg_vs_random(col, df, output=\"diff\", max_=max_)\n",
    "df_diff[\"SMILES\"] = df[\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_acqf = pd.DataFrame()\n",
    "non_zero_counts = rxn_lm - df_diff.isna().sum()\n",
    "df_results_acqf[\"AF\"] = df_diff.columns\n",
    "df_results_acqf['num_target_acc']            = non_zero_counts.values\n",
    "df_results_acqf['mean_vs_rd']                = list(df_diff.mean())\n",
    "df_results_acqf['median_vs_rd']              = list(df_diff.median())\n",
    "\n",
    "df_results_acqf\n",
    "#df_results_acqf.to_csv(f\"acqf_results_{rxn}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['random'] != max_]\n",
    "#df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_copy = df.copy() \n",
    "for col in df_copy.columns:\n",
    "    if 'acqf' in col:\n",
    "        df_copy[col] = df[col] - df['random']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = df.random.mean()\n",
    "for col in df_copy.columns:\n",
    "    if 'acqf' in col:\n",
    "        print(col, round(100*df_copy[col].mean()/random_data,1), \"% of random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regio_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
